{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline  \n",
    "\n",
    "def prepare_and_train_model(df):\n",
    "    \"\"\"\n",
    "    Prepare data and train an improved model for development trend score prediction\n",
    "    \"\"\"\n",
    "    X = df.drop('development_trend_score', axis=1)\n",
    "    y = df['development_trend_score']\n",
    "    \n",
    "    X = pd.get_dummies(X, columns=['urban_area_type'])\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', KNNImputer(n_neighbors=5)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('classifier', RandomForestClassifier(\n",
    "            n_estimators=200,\n",
    "            max_depth=15,\n",
    "            min_samples_split=5,\n",
    "            min_samples_leaf=2,\n",
    "            class_weight='balanced',\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # Fit the pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Print classification report\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"Test Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "\n",
    "    \n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X_train.columns,\n",
    "        'importance': pipeline.named_steps['classifier'].feature_importances_\n",
    "    })\n",
    "    feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 10 Most Important Features:\")\n",
    "    print(feature_importance.head(10))\n",
    "    \n",
    "    return pipeline, feature_importance\n",
    "\n",
    "def evaluate_with_cross_validation(X, y, pipeline):\n",
    "    \"\"\"\n",
    "    Evaluate the model using cross-validation\n",
    "    \"\"\"\n",
    "    scores = cross_val_score(pipeline, X, y, cv=5, scoring='accuracy')\n",
    "    print(f\"\\nCross-validation scores: {scores}\")\n",
    "    print(f\"Average CV score: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})\")\n",
    "\n",
    "# Example usage:\n",
    "# df = pd.read_csv('your_data.csv')\n",
    "# pipeline, feature_importance = prepare_and_train_model(df)\n",
    "# X = df.drop('development_trend_score', axis=1)\n",
    "# y = df['development_trend_score']\n",
    "# evaluate_with_cross_validation(X, y, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.12      0.06      0.08       204\n",
      "           2       0.23      0.11      0.15       403\n",
      "           3       0.40      0.74      0.52       804\n",
      "           4       0.23      0.09      0.13       390\n",
      "           5       0.07      0.03      0.04       199\n",
      "\n",
      "    accuracy                           0.35      2000\n",
      "   macro avg       0.21      0.21      0.18      2000\n",
      "weighted avg       0.27      0.35      0.28      2000\n",
      "\n",
      "Test Accuracy: 0.3455\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                          feature  importance\n",
      "15          proximity_to_highways    0.053081\n",
      "8                  retail_density    0.051246\n",
      "10         green_space_percentage    0.051167\n",
      "9       office_space_availability    0.050872\n",
      "17            housing_price_index    0.050817\n",
      "7               unemployment_rate    0.050535\n",
      "6   public_transport_availability    0.050358\n",
      "16                 internet_speed    0.049841\n",
      "13            crime_rate_per_1000    0.049813\n",
      "0              population_density    0.049769\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/imblearn/pipeline.py\", line 329, in fit\n    Xt, yt = self._fit(X, y, routed_params)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/imblearn/pipeline.py\", line 255, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/imblearn/pipeline.py\", line 1104, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1101, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/impute/_knn.py\", line 230, in fit\n    X = self._validate_data(\n        ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 633, in _validate_data\n    out = check_array(X, input_name=\"X\", **check_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1012, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py\", line 745, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/pandas/core/generic.py\", line 2153, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'Mixed'\n\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/imblearn/pipeline.py\", line 329, in fit\n    Xt, yt = self._fit(X, y, routed_params)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/imblearn/pipeline.py\", line 255, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/imblearn/pipeline.py\", line 1104, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1101, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/impute/_knn.py\", line 230, in fit\n    X = self._validate_data(\n        ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 633, in _validate_data\n    out = check_array(X, input_name=\"X\", **check_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1012, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py\", line 745, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/pandas/core/generic.py\", line 2153, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'Industrial'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m X \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevelopment_trend_score\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevelopment_trend_score\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m \u001b[43mevaluate_with_cross_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 67\u001b[0m, in \u001b[0;36mevaluate_with_cross_validation\u001b[0;34m(X, y, pipeline)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_with_cross_validation\u001b[39m(X, y, pipeline):\n\u001b[1;32m     64\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    Evaluate the model using cross-validation\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCross-validation scores: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscores\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage CV score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscores\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (+/- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscores\u001b[38;5;241m.\u001b[39mstd()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/notebooks/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/notebooks/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:712\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    710\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 712\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/notebooks/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/notebooks/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:443\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    422\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m    423\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    424\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    425\u001b[0m         clone(estimator),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[1;32m    441\u001b[0m )\n\u001b[0;32m--> 443\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "File \u001b[0;32m~/notebooks/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     )\n\u001b[0;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    539\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/imblearn/pipeline.py\", line 329, in fit\n    Xt, yt = self._fit(X, y, routed_params)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/imblearn/pipeline.py\", line 255, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/imblearn/pipeline.py\", line 1104, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1101, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/impute/_knn.py\", line 230, in fit\n    X = self._validate_data(\n        ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 633, in _validate_data\n    out = check_array(X, input_name=\"X\", **check_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1012, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py\", line 745, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/pandas/core/generic.py\", line 2153, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'Mixed'\n\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/imblearn/pipeline.py\", line 329, in fit\n    Xt, yt = self._fit(X, y, routed_params)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/imblearn/pipeline.py\", line 255, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/imblearn/pipeline.py\", line 1104, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1101, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/impute/_knn.py\", line 230, in fit\n    X = self._validate_data(\n        ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 633, in _validate_data\n    out = check_array(X, input_name=\"X\", **check_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1012, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py\", line 745, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/pandas/core/generic.py\", line 2153, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'Industrial'\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/urban_development_dataset.csv')\n",
    "pipeline, feature_importance = prepare_and_train_model(df)\n",
    "X = df.drop('development_trend_score', axis=1)\n",
    "y = df['development_trend_score']\n",
    "evaluate_with_cross_validation(X, y, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.multiclass      import OneVsOneClassifier\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répartition initiale des classes :\n",
      "development_trend_score\n",
      "3    4019\n",
      "2    2018\n",
      "4    1949\n",
      "1    1018\n",
      "5     996\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population_density</th>\n",
       "      <th>median_age</th>\n",
       "      <th>average_household_income</th>\n",
       "      <th>number_of_schools</th>\n",
       "      <th>number_of_hospitals</th>\n",
       "      <th>number_of_parks</th>\n",
       "      <th>public_transport_availability</th>\n",
       "      <th>unemployment_rate</th>\n",
       "      <th>retail_density</th>\n",
       "      <th>office_space_availability</th>\n",
       "      <th>...</th>\n",
       "      <th>air_quality_index</th>\n",
       "      <th>crime_rate_per_1000</th>\n",
       "      <th>fire_station_proximity</th>\n",
       "      <th>proximity_to_highways</th>\n",
       "      <th>internet_speed</th>\n",
       "      <th>housing_price_index</th>\n",
       "      <th>year</th>\n",
       "      <th>road_density</th>\n",
       "      <th>urban_area_type</th>\n",
       "      <th>development_trend_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5993.428306</td>\n",
       "      <td>28.215053</td>\n",
       "      <td>61965.724953</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.861705</td>\n",
       "      <td>37.189497</td>\n",
       "      <td>88712.383725</td>\n",
       "      <td>...</td>\n",
       "      <td>62.395034</td>\n",
       "      <td>41.802960</td>\n",
       "      <td>6.402334</td>\n",
       "      <td>17.249894</td>\n",
       "      <td>77.988714</td>\n",
       "      <td>90.010909</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>55.745540</td>\n",
       "      <td>Industrial</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4723.471398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.083094</td>\n",
       "      <td>46.340402</td>\n",
       "      <td>3626.311603</td>\n",
       "      <td>...</td>\n",
       "      <td>34.313537</td>\n",
       "      <td>39.794477</td>\n",
       "      <td>3.560183</td>\n",
       "      <td>12.198698</td>\n",
       "      <td>46.044637</td>\n",
       "      <td>100.535265</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>44.268702</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6295.377076</td>\n",
       "      <td>29.026189</td>\n",
       "      <td>36269.603084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.247585</td>\n",
       "      <td>4.089341</td>\n",
       "      <td>31.838015</td>\n",
       "      <td>49082.549371</td>\n",
       "      <td>...</td>\n",
       "      <td>35.430750</td>\n",
       "      <td>49.022339</td>\n",
       "      <td>5.456112</td>\n",
       "      <td>16.765462</td>\n",
       "      <td>34.875393</td>\n",
       "      <td>136.993995</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>73.174815</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8046.059713</td>\n",
       "      <td>36.104180</td>\n",
       "      <td>66591.684435</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.489689</td>\n",
       "      <td>30025.861163</td>\n",
       "      <td>...</td>\n",
       "      <td>46.964789</td>\n",
       "      <td>30.998953</td>\n",
       "      <td>9.443431</td>\n",
       "      <td>18.425252</td>\n",
       "      <td>71.182735</td>\n",
       "      <td>89.952283</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>79.516600</td>\n",
       "      <td>Industrial</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4531.693251</td>\n",
       "      <td>46.971785</td>\n",
       "      <td>25198.346488</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.838243</td>\n",
       "      <td>6.676002</td>\n",
       "      <td>48.426125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>67.517386</td>\n",
       "      <td>39.880218</td>\n",
       "      <td>8.398393</td>\n",
       "      <td>15.101962</td>\n",
       "      <td>108.795957</td>\n",
       "      <td>64.845688</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>47.145522</td>\n",
       "      <td>Industrial</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   population_density  median_age  average_household_income  \\\n",
       "0         5993.428306   28.215053              61965.724953   \n",
       "1         4723.471398         NaN                       NaN   \n",
       "2         6295.377076   29.026189              36269.603084   \n",
       "3         8046.059713   36.104180              66591.684435   \n",
       "4         4531.693251   46.971785              25198.346488   \n",
       "\n",
       "   number_of_schools  number_of_hospitals  number_of_parks  \\\n",
       "0                5.0                  2.0              3.0   \n",
       "1                4.0                  0.0              3.0   \n",
       "2                NaN                  2.0              0.0   \n",
       "3                5.0                  2.0              0.0   \n",
       "4                6.0                  0.0              0.0   \n",
       "\n",
       "   public_transport_availability  unemployment_rate  retail_density  \\\n",
       "0                            NaN           7.861705       37.189497   \n",
       "1                            NaN           5.083094       46.340402   \n",
       "2                       0.247585           4.089341       31.838015   \n",
       "3                       0.993784                NaN       64.489689   \n",
       "4                       0.838243           6.676002       48.426125   \n",
       "\n",
       "   office_space_availability  ...  air_quality_index  crime_rate_per_1000  \\\n",
       "0               88712.383725  ...          62.395034            41.802960   \n",
       "1                3626.311603  ...          34.313537            39.794477   \n",
       "2               49082.549371  ...          35.430750            49.022339   \n",
       "3               30025.861163  ...          46.964789            30.998953   \n",
       "4                        NaN  ...          67.517386            39.880218   \n",
       "\n",
       "   fire_station_proximity  proximity_to_highways  internet_speed  \\\n",
       "0                6.402334              17.249894       77.988714   \n",
       "1                3.560183              12.198698       46.044637   \n",
       "2                5.456112              16.765462       34.875393   \n",
       "3                9.443431              18.425252       71.182735   \n",
       "4                8.398393              15.101962      108.795957   \n",
       "\n",
       "   housing_price_index    year  road_density  urban_area_type  \\\n",
       "0            90.010909  2020.0     55.745540       Industrial   \n",
       "1           100.535265  2021.0     44.268702            Mixed   \n",
       "2           136.993995  2020.0     73.174815            Mixed   \n",
       "3            89.952283  2019.0     79.516600       Industrial   \n",
       "4            64.845688  2018.0     47.145522       Industrial   \n",
       "\n",
       "   development_trend_score  \n",
       "0                        4  \n",
       "1                        4  \n",
       "2                        5  \n",
       "3                        2  \n",
       "4                        1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv('./data/urban_development_dataset.csv')\n",
    "# resampled_data = []\n",
    "# classes = df['development_trend_score'].unique()\n",
    "# target_samples = 2000\n",
    "# for cls in classes:\n",
    "#     class_data = df[df['development_trend_score'] == cls]\n",
    "#     if len(class_data) > target_samples:\n",
    "#         resampled = resample(class_data, replace=False, n_samples=target_samples, random_state=42)\n",
    "#     else:\n",
    "#         resampled = resample(class_data, replace=True, n_samples=target_samples, random_state=42)\n",
    "#     resampled_data.append(resampled)\n",
    "\n",
    "# balanced_df = pd.concat(resampled_data)\n",
    "# df = balanced_df\n",
    "print(\"Répartition initiale des classes :\")\n",
    "print(df['development_trend_score'].value_counts())\n",
    "\n",
    "test_data = pd.read_csv('./data/urban_development_test_data.csv')\n",
    "common_columns = df.columns.intersection(test_data.columns)\n",
    "#definition of the X and Y\n",
    "Y = df['development_trend_score']\n",
    "# Y -= 1\n",
    "X = df[common_columns]\n",
    "\n",
    "\n",
    "test_data = test_data[common_columns]\n",
    "le = LabelEncoder()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing of Null data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'SMOTE(random_state=42)' (type <class 'imblearn.over_sampling._smote.base.SMOTE'>) doesn't",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 27\u001b[0m\n\u001b[1;32m      9\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[1;32m     10\u001b[0m         X, Y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, stratify\u001b[38;5;241m=\u001b[39mY\n\u001b[1;32m     11\u001b[0m     )\n\u001b[1;32m     13\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[1;32m     14\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimputer\u001b[39m\u001b[38;5;124m'\u001b[39m, KNNImputer(n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)),\n\u001b[1;32m     15\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m, StandardScaler()),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m         ))\n\u001b[1;32m     25\u001b[0m     ])\n\u001b[0;32m---> 27\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mClassification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/notebooks/.venv/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/notebooks/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:469\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    427\u001b[0m \n\u001b[1;32m    428\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and sequentially transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    468\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_method_params(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, props\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m--> 469\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/notebooks/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:386\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, routed_params)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, routed_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# shallow copy of steps - this should really be steps_\u001b[39;00m\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps)\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_steps\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;66;03m# Setup the memory\u001b[39;00m\n\u001b[1;32m    388\u001b[0m     memory \u001b[38;5;241m=\u001b[39m check_memory(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory)\n",
      "File \u001b[0;32m~/notebooks/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:256\u001b[0m, in \u001b[0;36mPipeline._validate_steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(t, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(t, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[1;32m    254\u001b[0m         t, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    255\u001b[0m     ):\n\u001b[0;32m--> 256\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    257\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll intermediate steps should be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    258\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformers and implement fit and transform \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    259\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor be the string \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (t, \u001b[38;5;28mtype\u001b[39m(t))\n\u001b[1;32m    261\u001b[0m         )\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# We allow last estimator to be None as an identity transformation\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    265\u001b[0m     estimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    268\u001b[0m ):\n",
      "\u001b[0;31mTypeError\u001b[0m: All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'SMOTE(random_state=42)' (type <class 'imblearn.over_sampling._smote.base.SMOTE'>) doesn't"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, Y, test_size=0.2, random_state=42, stratify=Y\n",
    "    )\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('imputer', KNNImputer(n_neighbors=5)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('classifier', RandomForestClassifier(\n",
    "            n_estimators=200,\n",
    "            max_depth=15,\n",
    "            min_samples_split=5,\n",
    "            min_samples_leaf=2,\n",
    "            class_weight='balanced',\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature importance analysis\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': pipeline.named_steps['classifier'].feature_importances_\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(pipeline, X, Y, cv=5, scoring='accuracy')\n",
    "print(f\"\\nCross-validation scores: {scores}\")\n",
    "print(f\"Average CV score: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39369/3869585995.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[numerical_features] = knn_imputer.fit_transform(X[numerical_features])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "population_density               0\n",
      "median_age                       0\n",
      "average_household_income         0\n",
      "number_of_schools                0\n",
      "number_of_hospitals              0\n",
      "number_of_parks                  0\n",
      "public_transport_availability    0\n",
      "unemployment_rate                0\n",
      "retail_density                   0\n",
      "office_space_availability        0\n",
      "green_space_percentage           0\n",
      "average_temperature              0\n",
      "air_quality_index                0\n",
      "crime_rate_per_1000              0\n",
      "fire_station_proximity           0\n",
      "proximity_to_highways            0\n",
      "internet_speed                   0\n",
      "housing_price_index              0\n",
      "year                             0\n",
      "road_density                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "numerical_features = [\n",
    "    \"population_density\", 'median_age', 'average_household_income', \n",
    "    'number_of_schools', 'number_of_hospitals', 'number_of_parks', \n",
    "    'public_transport_availability', 'unemployment_rate', 'retail_density', \n",
    "    'office_space_availability', 'green_space_percentage', 'average_temperature', \n",
    "    'air_quality_index', 'crime_rate_per_1000', 'fire_station_proximity', \n",
    "    'proximity_to_highways', 'internet_speed', 'road_density', \n",
    "    'housing_price_index', 'year'\n",
    "]\n",
    "# imputer = SimpleImputer(strategy='median') \n",
    "# numerical_features = [\"population_density\",'median_age', 'average_household_income', 'number_of_schools', 'number_of_hospitals','number_of_parks','public_transport_availability' ,'unemployment_rate', 'retail_density','office_space_availability','green_space_percentage','average_temperature','air_quality_index','crime_rate_per_1000','fire_station_proximity','proximity_to_highways','internet_speed','road_density','housing_price_index','year',  ]\n",
    "# df[numerical_features] = imputer.fit_transform(df[numerical_features])\n",
    "# df.isnull().sum()\n",
    "\n",
    "knn_imputer = KNNImputer(n_neighbors=5)  \n",
    "X[numerical_features] = knn_imputer.fit_transform(X[numerical_features])\n",
    "test_data[numerical_features] = knn_imputer.fit_transform(test_data[numerical_features])\n",
    "print(X.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalization of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns, index=X.index)\n",
    "# Y = le.fit_transform(Y)\n",
    "# Y = to_categorical(Y)\n",
    "scaled_data = scaler.transform(test_data)\n",
    "test_data_scaled = pd.DataFrame(scaled_data, columns=test_data.columns, index=test_data.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      population_density  median_age  average_household_income  \\\n",
      "5846            3.005547    0.709511                  0.467174   \n",
      "7544            1.098085    1.672421                  0.394031   \n",
      "4545            0.614504    1.677495                  0.075691   \n",
      "6680            0.303540    0.358588                  0.081952   \n",
      "5855            1.816925    0.285117                  0.136801   \n",
      "...                  ...         ...                       ...   \n",
      "6520            0.337106    0.030071                  0.194442   \n",
      "8482            1.970142    0.158172                  0.132746   \n",
      "6877            0.730339    0.983954                  0.122113   \n",
      "4907            1.158970    0.778371                  0.216804   \n",
      "9991            0.396137    0.547157                  0.580031   \n",
      "\n",
      "      number_of_schools  number_of_hospitals  number_of_parks  \\\n",
      "5846           0.904290             0.734323         0.042640   \n",
      "7544           0.921857             0.724780         1.665695   \n",
      "4545           1.834931             1.463874         1.750975   \n",
      "6680           0.921857             0.724780         1.096250   \n",
      "5855           0.904290             0.724780         1.181530   \n",
      "...                 ...                  ...              ...   \n",
      "6520           0.008784             0.734323         1.665695   \n",
      "8482           0.008784             0.004771         1.665695   \n",
      "6877           1.360827             1.463874         1.096250   \n",
      "4907           0.008784             1.454331         1.665695   \n",
      "9991           0.921857             1.454331         0.526805   \n",
      "\n",
      "      public_transport_availability  unemployment_rate  retail_density  \\\n",
      "5846                       1.661714           0.676561        0.389171   \n",
      "7544                       0.860156           0.408425        1.053570   \n",
      "4545                       0.567646           0.450638        0.259088   \n",
      "6680                       0.507904           0.481714        0.136672   \n",
      "5855                       1.156371           0.255551        0.181839   \n",
      "...                             ...                ...             ...   \n",
      "6520                       0.621368           0.725997        0.134069   \n",
      "8482                       0.049284           0.086024        2.136485   \n",
      "6877                       1.112538           0.598145        0.027506   \n",
      "4907                       1.559377           0.521242        0.288927   \n",
      "9991                       1.076437           0.923628        0.203465   \n",
      "\n",
      "      office_space_availability  green_space_percentage  average_temperature  \\\n",
      "5846                   0.094019                0.165950             0.496927   \n",
      "7544                   0.564808                0.546394             0.186338   \n",
      "4545                   0.689610                1.413786             0.145440   \n",
      "6680                   0.822877                0.530839             0.759178   \n",
      "5855                   1.210280                1.173372             0.331746   \n",
      "...                         ...                     ...                  ...   \n",
      "6520                   0.816699                1.007291             0.108449   \n",
      "8482                   0.284073                1.112627             0.492620   \n",
      "6877                   0.456343                1.529952             0.027979   \n",
      "4907                   1.720092                1.521766             0.118416   \n",
      "9991                   1.489014                1.082961             0.989872   \n",
      "\n",
      "      air_quality_index  crime_rate_per_1000  fire_station_proximity  \\\n",
      "5846           0.079395             1.367572                1.542804   \n",
      "7544           1.795538             0.947732                0.450036   \n",
      "4545           0.249442             0.753976                0.420888   \n",
      "6680           1.013586             1.417620                1.044928   \n",
      "5855           0.611015             0.927522                0.136525   \n",
      "...                 ...                  ...                     ...   \n",
      "6520           0.879654             0.082136                0.529142   \n",
      "8482           0.855014             1.407210                0.461891   \n",
      "6877           0.004619             0.089652                1.025411   \n",
      "4907           1.791744             0.121934                1.687323   \n",
      "9991           0.746351             2.028096                0.258246   \n",
      "\n",
      "      proximity_to_highways  internet_speed  housing_price_index      year  \\\n",
      "5846               1.549664        2.143272             0.562395  1.467642   \n",
      "7544               0.234195        0.934351             0.423602  1.467642   \n",
      "4545               0.116330        0.588630             0.031368  1.395686   \n",
      "6680               1.227069        0.768731             0.373494  1.395686   \n",
      "5855               1.246869        1.239464             0.618401  0.751810   \n",
      "...                     ...             ...                  ...       ...   \n",
      "6520               1.378740        0.286653             1.450468  0.035978   \n",
      "8482               1.395571        0.236431             0.118640  0.679854   \n",
      "6877               1.110270        0.519397             1.489752  1.395686   \n",
      "4907               0.062917        1.241305             0.302659  0.679854   \n",
      "9991               0.351528        0.444119             1.156168  1.467642   \n",
      "\n",
      "      road_density  \n",
      "5846      2.889307  \n",
      "7544      1.019799  \n",
      "4545      0.702798  \n",
      "6680      0.210194  \n",
      "5855      1.661923  \n",
      "...            ...  \n",
      "6520      0.145818  \n",
      "8482      2.278625  \n",
      "6877      0.699704  \n",
      "4907      1.262179  \n",
      "9991      0.066409  \n",
      "\n",
      "[10000 rows x 20 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import zscore\n",
    "z_scores = np.abs(zscore(X_scaled)) \n",
    "outlier_mask = (z_scores > 3).any(axis=1)\n",
    "plt.figure(figsize=(10, 6))\n",
    "print(z_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trying some changes on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_scaled, Y)\n",
    "importances = model.feature_importances_\n",
    "threshold = 0.\n",
    "important_features = importances > threshold\n",
    "X_selected = X_scaled[:, important_features]\n",
    "test_data_selected = test_data.iloc[:, important_features]\n",
    "\n",
    "print(f\"Selected Features: {len(important_features)}\")\n",
    "\n",
    "# Optional: View the first few rows of the selected data\n",
    "print(\"Selected data (X):\")\n",
    "print(X_selected[:5])\n",
    "print(\"Selected test data:\")\n",
    "print(test_data_selected.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled['community_services'] = X_scaled['number_of_schools'] + X_scaled['number_of_hospitals'] + X_scaled['number_of_parks']\n",
    "X_scaled['accessibility'] = X_scaled['public_transport_availability'] * X_scaled['road_density']\n",
    "X_scaled.shape\n",
    "X_new = X_scaled\n",
    "X_new = X_scaled.drop(columns=['number_of_schools', 'number_of_hospitals', 'number_of_parks', 'public_transport_availability', 'road_density'])\n",
    "\n",
    "test_data_scaled['community_services'] = test_data_scaled['number_of_schools'] + test_data_scaled['number_of_hospitals'] + test_data_scaled['number_of_parks']\n",
    "test_data_scaled['accessibility'] = test_data_scaled['public_transport_availability'] * test_data_scaled['road_density']\n",
    "test_data_scaled.shape\n",
    "test_data_new = test_data_scaled.drop(columns=['number_of_schools', 'number_of_hospitals', 'number_of_parks', 'public_transport_availability', 'road_density'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 17) (2000, 17) (8000,) (2000,)\n"
     ]
    }
   ],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(X_new, Y, test_size=0.2, random_state=42)\n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)\n",
    "# train_x, train_y = X, Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.215\n",
      "Classification Report for SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.30      0.28       415\n",
      "           1       0.18      0.14      0.16       395\n",
      "           2       0.19      0.16      0.17       387\n",
      "           3       0.22      0.25      0.23       410\n",
      "           4       0.20      0.22      0.21       393\n",
      "\n",
      "    accuracy                           0.21      2000\n",
      "   macro avg       0.21      0.21      0.21      2000\n",
      "weighted avg       0.21      0.21      0.21      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "\n",
    "\n",
    "model = svm.SVC(kernel='linear', gamma='scale' , C=0.1)\n",
    "model.fit(train_x,train_y)\n",
    "\n",
    "# ovo_model = OneVsOneClassifier(model)\n",
    "# ovo_model.fit(train_x, train_y)\n",
    "y_pred = model.predict(test_x)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"Test Accuracy: {accuracy_score(test_y, y_pred)}\")\n",
    "print(f\"Classification Report for SVM:\\n{classification_report(test_y, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for Random Forest: 0.61\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.79      0.85       415\n",
      "           1       0.34      0.42      0.38       395\n",
      "           2       0.34      0.42      0.38       387\n",
      "           3       0.72      0.57      0.64       410\n",
      "           4       0.93      0.84      0.88       393\n",
      "\n",
      "    accuracy                           0.61      2000\n",
      "   macro avg       0.65      0.61      0.62      2000\n",
      "weighted avg       0.65      0.61      0.63      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# rfm = RandomForestClassifier(max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100, random_state=42)\n",
    "rfm = RandomForestClassifier(random_state=42, n_estimators=200)\n",
    "# rfm.fit(X, Y)\n",
    "rfm.fit(train_x, train_y)\n",
    "y_pred_rf = rfm.predict(test_x)\n",
    "\n",
    "print(f\"Test Accuracy for Random Forest: {accuracy_score(test_y, y_pred_rf)}\")\n",
    "print(f\"Classification Report for Random Forest:\\n{classification_report(test_y, y_pred_rf)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1991 - loss: 1.6975 - val_accuracy: 0.2194 - val_loss: 1.6110\n",
      "Epoch 2/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2188 - loss: 1.6148 - val_accuracy: 0.2113 - val_loss: 1.6080\n",
      "Epoch 3/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2324 - loss: 1.6085 - val_accuracy: 0.2288 - val_loss: 1.6056\n",
      "Epoch 4/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2507 - loss: 1.5907 - val_accuracy: 0.2288 - val_loss: 1.6021\n",
      "Epoch 5/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2615 - loss: 1.5825 - val_accuracy: 0.2544 - val_loss: 1.5992\n",
      "Epoch 6/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2637 - loss: 1.5800 - val_accuracy: 0.2419 - val_loss: 1.5964\n",
      "Epoch 7/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2845 - loss: 1.5639 - val_accuracy: 0.2412 - val_loss: 1.5950\n",
      "Epoch 8/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2880 - loss: 1.5604 - val_accuracy: 0.2444 - val_loss: 1.5928\n",
      "Epoch 9/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3020 - loss: 1.5485 - val_accuracy: 0.2556 - val_loss: 1.5890\n",
      "Epoch 10/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3037 - loss: 1.5412 - val_accuracy: 0.2625 - val_loss: 1.5843\n",
      "Epoch 11/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3124 - loss: 1.5401 - val_accuracy: 0.2631 - val_loss: 1.5835\n",
      "Epoch 12/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3082 - loss: 1.5408 - val_accuracy: 0.2600 - val_loss: 1.5802\n",
      "Epoch 13/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3160 - loss: 1.5320 - val_accuracy: 0.2612 - val_loss: 1.5770\n",
      "Epoch 14/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3304 - loss: 1.5264 - val_accuracy: 0.2731 - val_loss: 1.5699\n",
      "Epoch 15/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3355 - loss: 1.5135 - val_accuracy: 0.2794 - val_loss: 1.5717\n",
      "Epoch 16/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3517 - loss: 1.4956 - val_accuracy: 0.2794 - val_loss: 1.5689\n",
      "Epoch 17/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3346 - loss: 1.4949 - val_accuracy: 0.2862 - val_loss: 1.5652\n",
      "Epoch 18/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3393 - loss: 1.4889 - val_accuracy: 0.2850 - val_loss: 1.5644\n",
      "Epoch 19/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3450 - loss: 1.4848 - val_accuracy: 0.3013 - val_loss: 1.5605\n",
      "Epoch 20/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3634 - loss: 1.4763 - val_accuracy: 0.2937 - val_loss: 1.5556\n",
      "Epoch 21/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3573 - loss: 1.4732 - val_accuracy: 0.2981 - val_loss: 1.5541\n",
      "Epoch 22/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3710 - loss: 1.4624 - val_accuracy: 0.3100 - val_loss: 1.5494\n",
      "Epoch 23/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3620 - loss: 1.4606 - val_accuracy: 0.3031 - val_loss: 1.5488\n",
      "Epoch 24/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3796 - loss: 1.4520 - val_accuracy: 0.3025 - val_loss: 1.5468\n",
      "Epoch 25/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3743 - loss: 1.4429 - val_accuracy: 0.3094 - val_loss: 1.5414\n",
      "Epoch 26/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3714 - loss: 1.4448 - val_accuracy: 0.2988 - val_loss: 1.5416\n",
      "Epoch 27/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3670 - loss: 1.4413 - val_accuracy: 0.2994 - val_loss: 1.5387\n",
      "Epoch 28/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3829 - loss: 1.4345 - val_accuracy: 0.3019 - val_loss: 1.5363\n",
      "Epoch 29/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3859 - loss: 1.4275 - val_accuracy: 0.3131 - val_loss: 1.5382\n",
      "Epoch 30/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3775 - loss: 1.4304 - val_accuracy: 0.3187 - val_loss: 1.5350\n",
      "Epoch 31/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3949 - loss: 1.4163 - val_accuracy: 0.3206 - val_loss: 1.5281\n",
      "Epoch 32/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3830 - loss: 1.4111 - val_accuracy: 0.3262 - val_loss: 1.5283\n",
      "Epoch 33/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3951 - loss: 1.4047 - val_accuracy: 0.3181 - val_loss: 1.5262\n",
      "Epoch 34/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3926 - loss: 1.4047 - val_accuracy: 0.3244 - val_loss: 1.5261\n",
      "Epoch 35/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4093 - loss: 1.3884 - val_accuracy: 0.3250 - val_loss: 1.5219\n",
      "Epoch 36/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3973 - loss: 1.4049 - val_accuracy: 0.3288 - val_loss: 1.5231\n",
      "Epoch 37/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3971 - loss: 1.4037 - val_accuracy: 0.3431 - val_loss: 1.5196\n",
      "Epoch 38/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3928 - loss: 1.4060 - val_accuracy: 0.3288 - val_loss: 1.5182\n",
      "Epoch 39/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4182 - loss: 1.3828 - val_accuracy: 0.3325 - val_loss: 1.5136\n",
      "Epoch 40/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4096 - loss: 1.3820 - val_accuracy: 0.3419 - val_loss: 1.5103\n",
      "Epoch 41/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4126 - loss: 1.3788 - val_accuracy: 0.3388 - val_loss: 1.5105\n",
      "Epoch 42/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4086 - loss: 1.3752 - val_accuracy: 0.3269 - val_loss: 1.5035\n",
      "Epoch 43/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4165 - loss: 1.3786 - val_accuracy: 0.3331 - val_loss: 1.5036\n",
      "Epoch 44/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4233 - loss: 1.3619 - val_accuracy: 0.3388 - val_loss: 1.5062\n",
      "Epoch 45/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4073 - loss: 1.3692 - val_accuracy: 0.3475 - val_loss: 1.4996\n",
      "Epoch 46/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4146 - loss: 1.3737 - val_accuracy: 0.3544 - val_loss: 1.4945\n",
      "Epoch 47/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4284 - loss: 1.3489 - val_accuracy: 0.3487 - val_loss: 1.4933\n",
      "Epoch 48/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4337 - loss: 1.3467 - val_accuracy: 0.3487 - val_loss: 1.4888\n",
      "Epoch 49/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4490 - loss: 1.3403 - val_accuracy: 0.3512 - val_loss: 1.4931\n",
      "Epoch 50/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4200 - loss: 1.3553 - val_accuracy: 0.3656 - val_loss: 1.4872\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3983 - loss: 1.4599\n",
      "Loss sur le test : 1.4749\n",
      "Précision sur le test : 0.3830\n"
     ]
    }
   ],
   "source": [
    "# print(train_y.shape)\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "train_y = to_categorical(train_y)\n",
    "test_y = to_categorical(test_y)\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(train_x.shape[1],)),  \n",
    "    Dropout(0.3),  \n",
    "    Dense(64, activation='relu'), \n",
    "    Dropout(0.3),\n",
    "    Dense(train_y.shape[1], activation='softmax')  \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(train_x, train_y, validation_split=0.2, epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "# Évaluation du modèle\n",
    "test_loss, test_accuracy = model.evaluate(test_x, test_y)\n",
    "print(f\"Loss sur le test : {test_loss:.4f}\")\n",
    "print(f\"Précision sur le test : {test_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# y_true = np.argmax(test_y, axis=1)\n",
    "# print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
    "# print(f\"Classification Report:\\n{classification_report(y_true, y_pred)}\")\n",
    "# # Prédictions\n",
    "# y_pred = model.predict(test_x)\n",
    "# print(f\"Test Accuracy for Random Forest: {accuracy_score(test_y, y_pred_rf)}\")\n",
    "# print(f\"Classification Report for Random Forest:\\n{classification_report(test_y, y_pred_rf)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Test Accuracy for NN: 0.383\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.51      0.51       415\n",
      "           2       0.26      0.18      0.21       395\n",
      "           3       0.26      0.26      0.26       387\n",
      "           4       0.44      0.34      0.38       410\n",
      "           5       0.41      0.62      0.49       393\n",
      "\n",
      "    accuracy                           0.38      2000\n",
      "   macro avg       0.37      0.38      0.37      2000\n",
      "weighted avg       0.38      0.38      0.37      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(test_x), axis=1)\n",
    "y_pred +=1\n",
    "y_true = np.argmax(test_y, axis=1)\n",
    "y_true +=1\n",
    "y_true[:10], y_pred[:10]\n",
    "print(f\"Test Accuracy for NN: {accuracy_score(y_true, y_pred)}\")\n",
    "print(f\"Classification Report for Random Forest:\\n{classification_report(y_true, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "export result to csv from the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved at: ./test/development_trend_predictions_classification.csv\n"
     ]
    }
   ],
   "source": [
    "# output = np.argmax(model.predict(test_data), axis=1)\n",
    "# output += 1\n",
    "output = rfm.predict(test_data_new) #here changing the model \n",
    "output += 1\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": test_data.index + 1,  \n",
    "    \"development_trend_score\": output\n",
    "})\n",
    "submission_file_path = './test/development_trend_predictions_classification.csv'\n",
    "submission.to_csv(submission_file_path, index=False)\n",
    "print(f\"Submission file saved at: {submission_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.3995\n",
      "Classification Report for Gaussian Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       184\n",
      "           1       0.12      0.01      0.01       387\n",
      "           2       0.40      0.99      0.57       808\n",
      "           3       0.00      0.00      0.00       410\n",
      "           4       0.00      0.00      0.00       211\n",
      "\n",
      "    accuracy                           0.40      2000\n",
      "   macro avg       0.11      0.20      0.12      2000\n",
      "weighted avg       0.19      0.40      0.23      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/self-ouss/notebooks/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train a Gaussian Naive Bayes model\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(train_x, train_y)\n",
    "\n",
    "# Predict on the test set\n",
    "nb_y_pred = nb_model.predict(test_x)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"Test Accuracy: {accuracy_score(test_y, nb_y_pred)}\")\n",
    "print(f\"Classification Report for Gaussian Naive Bayes:\\n{classification_report(test_y, nb_y_pred)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
